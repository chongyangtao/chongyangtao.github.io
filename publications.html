<!-- https://logos.textgiraffe.com/logos/logo-name/Tao-designstyle-friday-m.png -->
<HTML>
<HEAD>
<meta http-equiv="content-type" content="text/html; charset=windows-1252">
<link href="logo.png" rel="shortcut icon" />
<title><strong>Chongyang Tao</strong></title>
    <link rel="stylesheet" href="inde_files/dyerlike.css"/>
    <link rel="stylesheet" href="inde_files/pygments.css"/>
</HEAD>
<BODY>
<header>
<nav>
<ul>
<ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="publications.html">Research</a></li>
    <li><a href="service.html">Service</a></li>
    <li><a href="useful.html">Useful</a></li>
    <li><a href="mailto:chongyangtao@gmail.com">Contact</a></li> 
</ul>

</ul>
</nav>
<h2><strong>Chongyang Tao</strong></h2> 
</header>

<!--
<section>
<h2> Preprints </h2>
<ul>
</ul>
</section>
-->

<section>
<h2> <strong>Research Experiences</strong></h2>
<ul>
<li> 2022/11 - Now: Senior Applied Scientist, Microsoft Bing Tech Team</li>
    <ul style="list-style-type:circle">
        <li> Mainly focus on the improvement and research for <a href="https://www.bing.com/" target="_blank">BING Search & Ads.</a>    </li>
        <li> Research Interests: 1) Representation learning in IR; 2) Effective IR (Distillation); 3) LLMs for search & Generative IR;  </li>

        <details>
        <summary> Highlights </summary>
            <!-- <dd>- Highlight 1:
                    <u><a href="none" target="_blank">LED</a></u> (WWW'23), 
                    <u><a href="none" target="_blank">HypeR</a></u> (ICLR'23), 
                    <u><a href="none" target="_blank">LexMAE</a></u> (ICLR'23), 
                    <u><a href="none" target="_blank">UnifieR</a></u> (KDD'23), 
                    <u><a href="none" target="_blank">R<sup>2</sup>anker </a></u>(ACL'23), <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                    <u><a href="none" target="_blank">PCL</a></u>(EMNLP'22), 
                    <u><a href="none" target="_blank">LexLIP </a></u>(ICCV'23)
                </dd>
            <dd>- Highlight 2:
                    <u><a href="none" target="_blank">ADAM</a></u> (arxiv'22), 
                    <u><a href="https://arxiv.org/pdf/2212.10423.pdf" target="_blank">FGD</a></u> (arxiv'22),
                    <u><a href="none" target="_blank">MGSKD</a></u> (ACL'22),
                    <u><a href="none" target="_blank">ContextualKD</a></u> (EMNLP'22)  
                    <u><a href="none" target="_blank">CoRE</a></u> (ACL'23), 
                </dd>
            <dd>- Highlight 3:
                    <u><a href="none" target="_blank">InteR</a></u> (arxiv'23), 
                    <u><a href="none" target="_blank">WizardLM</a></u> (arxiv'23), 
                    <u><a href="none" target="_blank">LameR</a></u> (arxiv'23), 
                    <u><a href="none" target="_blank">PKG</a></u> (arxiv'23)
                </dd> -->

        <!-- <table border="1px solid #cc"> -->
        <table style="border:1px solid gray;margin-left:30px;margin-right:30px;border-spacing:8px;">
          <tr>
            <td style="white-space:nowrap;">Highlight 1:</td>
            <td>
                <u><a href="https://arxiv.org/pdf/2208.13661.pdf" target="_blank">LED</a></u> (WWW'23), 
                <u><a href="https://openreview.net/forum?id=kUf4BcWXGJr" target="_blank">HypeR</a></u> (ICLR'23), 
                <u><a href="https://arxiv.org/pdf/2208.14754.pdf" target="_blank">LexMAE</a></u> (ICLR'23), 
                <u><a href="https://arxiv.org/pdf/2205.11194.pdf" target="_blank">UnifieR</a></u> (KDD'23), 
                <u><a href="https://aclanthology.org/2023.findings-acl.332.pdf" target="_blank">R<sup>2</sup>anker </a></u>(ACL'23),
                <u><a href="https://aclanthology.org/2022.emnlp-main.826.pdf" target="_blank">PCL</a></u>(EMNLP'22), 
                <u><a href="https://arxiv.org/pdf/2302.02908" target="_blank">LexLIP</a></u>(ICCV'23)
            </td>
          </tr>
          
          <tr>
            <td style="white-space:nowrap;">Highlight 2:</td>
            <td> 
                <u><a href="https://arxiv.org/pdf/2212.10192" target="_blank">ADAM</a></u> (arxiv'22), 
                <u><a href="https://arxiv.org/pdf/2212.10423.pdf" target="_blank">FGD</a></u> (arxiv'22),
                <u><a href="https://aclanthology.org/2022.acl-long.71.pdf" target="_blank">MGSKD</a></u> (ACL'22),
                <u><a href="https://aclanthology.org/2022.emnlp-main.729.pdf" target="_blank">ContextualKD</a></u> (EMNLP'22),
                <u><a href="https://aclanthology.org/2023.acl-long.174.pdf" target="_blank">CoRE</a></u> (ACL'23)
          </tr>

          <tr>
            <td style="white-space:nowrap;">Highlight 3:</td>
            <td>    
                <u><a href="https://arxiv.org/pdf/2304.12244" target="_blank">WizardLM</a></u> (arxiv'23), 
                <u><a href="https://arxiv.org/pdf/2305.07402" target="_blank">InteR</a></u> (arxiv'23), 
                <u><a href="https://arxiv.org/pdf/2304.14233" target="_blank">LameR</a></u> (arxiv'23), 
                <u><a href="https://arxiv.org/pdf/2305.04757" target="_blank">PKG</a></u> (arxiv'23)</td>
            </tr>
        </table>

        </details>

        <!-- <p style="border: 1.2px dotted gray; "> 
            <br style="line-height: 3px" />
            &nbsp;&nbsp; Highlight 1:
                <u><a href="https://arxiv.org/pdf/2208.13661.pdf" target="_blank">LED</a></u> (WWW'23), 
                <u><a href="https://openreview.net/forum?id=kUf4BcWXGJr" target="_blank">HypeR</a></u> (ICLR'23), 
                <u><a href="https://arxiv.org/pdf/2208.14754.pdf" target="_blank">LexMAE</a></u> (ICLR'23), 
                <u><a href="https://arxiv.org/pdf/2205.11194.pdf" target="_blank">UnifieR</a></u> (KDD'23), 
                <u><a href="https://aclanthology.org/2023.findings-acl.332.pdf" target="_blank">R<sup>2</sup>anker </a></u>(ACL'23), <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <u><a href="https://aclanthology.org/2022.emnlp-main.826.pdf" target="_blank">PCL</a></u>(EMNLP'22), 
                <u><a href="none" target="_blank">LexLIP</a></u>(ICCV'23)
            <br>
            &nbsp;&nbsp; Highlight 2: 
                <u><a href="none" target="_blank">ADAM</a></u> (arxiv'22), 
                <u><a href="https://arxiv.org/pdf/2212.10423.pdf" target="_blank">FGD</a></u> (arxiv'22),
                <u><a href="none" target="_blank">MGSKD</a></u> (ACL'22),
                <u><a href="https://aclanthology.org/2022.emnlp-main.729.pdf" target="_blank">ContextualKD</a></u> (EMNLP'22),
                <u><a href="none" target="_blank">CoRE</a></u> (ACL'23)
            <br>
            &nbsp;&nbsp; Highlight 3: 
                <u><a href="none" target="_blank">InteR</a></u> (arxiv'23), 
                <u><a href="none" target="_blank">WizardLM</a></u> (arxiv'23), 
                <u><a href="none" target="_blank">LameR</a></u> (arxiv'23), 
                <u><a href="none" target="_blank">PKG</a></u> (arxiv'23)
            <br> 
            <br style="line-height: 8px" />
        </p> -->

    </ul>


<li> 2020/07 - 2022/11: Postdoctoral Applied Scientist, Microsoft Bing Tech Team</li>
    <ul style="list-style-type:circle">
        <li>Working with Dr. Daxin Jiang (Microsoft VP).</li>
        <li> Mainly responsible for the research and improvement of <a href="https://blogs.bing.com/search-quality-insights/2017-05/making-search-conversational-finding-and-chatting-with-bots-on-bing" target="_blank">Chat with BING</a> (a virtual assistant for BING).</li>
        <li> Research Interests: 1) Knowledge-driven conversation; 2) Multi-party conversation; 3) Multi-modal conversation </li>
        <!-- 1) Universal dialogue understanding model; 2 -->

        <!-- <dd> Highlight 1:
                <u><a href="none" target="_blank">DRD</a></u> (ICLR'20), 
                <u><a href="none" target="_blank">KnowledGPT</a></u> (EMNLP'20), 
                <u><a href="none" target="_blank">ZRKGC</a></u> (NeurIPS'21), 
                <u><a href="none" target="_blank">TegTok</a></u> (ACL'21), <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <u><a href="none" target="_blank">PTKGC</a></u> (ACL'21), 
                <u><a href="none" target="_blank">PersonaKGC</a></u> (ACL'22), 
                <u><a href="none" target="_blank">DivKGC</a></u> (EMNLP'22)
            </dd> 
        <dd> Highlight 2:
                <u><a href="none" target="_blank">MPC-BERT</a></u> (ACL'21), 
                <u><a href="none" target="_blank">HeterMPC</a></u> (ACL'22), 
                <u><a href="none" target="_blank">MPCSurvey</a></u> (IJCAI'22), 
                <u><a href="none" target="_blank">BERT-SL</a></u> (AAAI'21)
            </dd>
        <dd> Highlight 3:
                <u><a href="none" target="_blank">Maria</a></u> (ACL'21), 
                <u><a href="none" target="_blank">MMDial</a></u> (ACL'22), 
                <u><a href="none" target="_blank">VideoDial</a></u> (EMNLP'22)
            </dd> -->
        <details>
        <summary>Highlights</summary>
        <!-- <p>这里是被展开的内容。</p> -->

        <table style="border:1px solid gray;margin-left:30px;margin-right:30px;border-spacing:8px;">
          <tr>
            <td style="white-space:nowrap;">Highlight 1:</td>
            <td>
                <u><a href="https://openreview.net/pdf?id=rJeIcTNtvS" target="_blank">DRD</a></u> (ICLR'20), 
                <u><a href="https://www.aclweb.org/anthology/2020.emnlp-main.272" target="_blank">KnowledGPT</a></u> (EMNLP'20), 
                <u><a href="https://arxiv.org/pdf/2008.12918.pdf" target="_blank">ZRKGC</a></u> (NeurIPS'21), 
                <u><a href="https://aclanthology.org/2022.findings-acl.125.pdf" target="_blank">TegTok</a></u> (ACL'21),
                <u><a href="https://aclanthology.org/2021.acl-long.343.pdf" target="_blank">PTKGC</a></u> (ACL'21), 
                <u><a href="https://aclanthology.org/2022.acl-long.270.pdf" target="_blank">PersonaKGC</a></u> (ACL'22), 
                <u><a href="https://aclanthology.org/2022.emnlp-main.123.pdf" target="_blank">DivKGC</a></u> (EMNLP'22)
            </td>
          </tr>
          
          <tr>
            <td style="white-space:nowrap;">Highlight 2:</td>
            <td> 
                <u><a href="https://aclanthology.org/2021.acl-long.285.pdf" target="_blank">MPC-BERT</a></u> (ACL'21), 
                <u><a href="https://aclanthology.org/2022.acl-long.349.pdf" target="_blank">HeterMPC</a></u> (ACL'22), 
                <u><a href="https://www.ijcai.org/proceedings/2022/768" target="_blank">MPCSurvey</a></u> (IJCAI'22), 
                <u><a href="https://arxiv.org/pdf/2009.06265.pdf" target="_blank">BERT-SL</a></u> (AAAI'21)
            </td>
          </tr>

          <tr>
            <td style="white-space:nowrap;">Highlight 3:</td>
            <td>    
                <u><a href="https://arxiv.org/pdf/2105.13073.pdf" target="_blank">Maria</a></u> (ACL'21), 
                <u><a href="https://aclanthology.org/2023.acl-long.405.pdf" target="_blank">MMDial</a></u> (ACL'22), 
                <u><a href="https://aclanthology.org/2022.findings-emnlp.442.pdf" target="_blank">VideoDial</a></u> (EMNLP'22)
            </td>
            </tr>
        </table>

                </details>
        <!-- <u><a href="https://www.ijcai.org/Proceedings/2019/0756.pdf" target="_blank">DGMN </a></u> (IJCAI'19),  -->

        <!-- <p style="border: 1.2px dotted gray; "> 
            <br style="line-height: 3px" />
            &nbsp;&nbsp; Highlight 1: 
                <u><a href="none" target="_blank">DRD</a></u> (ICLR'20), 
                <u><a href="none" target="_blank">KnowledGPT</a></u> (EMNLP'20), 
                <u><a href="none" target="_blank">ZRKGC</a></u> (NeurIPS'21), 
                <u><a href="none" target="_blank">TegTok</a></u> (ACL'21), 
                <u><a href="none" target="_blank">PTKGC</a></u> (ACL'21), <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                <u><a href="none" target="_blank">PersonaKGC</a></u> (ACL'22), 
                <u><a href="https://aclanthology.org/2022.emnlp-main.123.pdf" target="_blank">DivKGC</a></u> (EMNLP'22)
            <br>
            &nbsp;&nbsp; Highlight 2: 
                <u><a href="none" target="_blank">MPC-BERT</a></u> (ACL'21), 
                <u><a href="none" target="_blank">HeterMPC</a></u> (ACL'22), 
                <u><a href="https://www.ijcai.org/proceedings/2022/768" target="_blank">MPCSurvey</a></u> (IJCAI'22), 
                <u><a href="none" target="_blank">BERT-SL</a></u> (AAAI'21)
            <br>
            &nbsp;&nbsp; Highlight 3: 
                <u><a href="none" target="_blank">Maria</a></u> (ACL'21), 
                <u><a href="none" target="_blank">MMDial</a></u> (ACL'22), 
                <u><a href="https://aclanthology.org/2022.findings-emnlp.442.pdf" target="_blank">VideoDial</a></u> (EMNLP'22)
            <br> 
            <br style="line-height: 8px" />
        </p> -->
</ul>



<li> 2016/11 - 2020/05: Ph.D. Candidate, Peking University, Beijing, China</li>
    <ul style="list-style-type:circle">
        <li>Research Interests: 1) Human-centered dialogue generation; 2) Dialogue retrieval & context modeling; 3) Open-domain dialogue evaluation.</li>
            <!-- <u><a href="https://www.ijcai.org/Proceedings/2019/0756.pdf" target="_blank">DGMN </a></u> (IJCAI'19), 
            <u><a href="none" target="_blank">WDMN </a></u> (TOIS'21),   -->

        <!-- <dd>- Highlight 1:
            <u><a href="https://www.ijcai.org/proceedings/2018/0614.pdf" target="_blank">CMHA </a></u> (IJCAI'18), 
            <u><a href="https://arxiv.org/pdf/2004.14592.pdf" target="_blank">EnsembleGAN </a></u> (SIGIR'19), 
            <u><a href="none" target="_blank">MetaDial </a></u> (ACL'19), 
            <u><a href="none" target="_blank">ProphetChat </a></u> (ACL'22) 
        </dd>
        <dd>- Highlight 2:
            [Context Modeling]
            <u><a href="https://aclanthology.org/P19-1001.pdf" target="_blank">IOI </a></u> (ACL'19),  
            <u><a href="https://dl.acm.org/doi/10.1145/3289600.3290985" target="_blank">MRFN </a></u> (WSDM'19), 
            <u><a href="none" target="_blank">ECMO</a></u> (SIGIR'20), 
            <u><a href="none" target="_blank">IR2 </a></u> (EMNLP'22),
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            [Learning to Rank]
            <u><a href="https://aclanthology.org/P19-1370.pdf" target="_blank">CoT</a></u> (ACL'19), 
            <u><a href="https://aclanthology.org/D19-1128.pdf" target="_blank">HardSamp </a></u> (EMNLP'20), 
            <u><a href="none" target="_blank">UdaRS</a></u> (WSDM'22) 
        </dd>
        <dd>- Highlight 3:
            <u><a href="https://arxiv.org/pdf/1701.03079.pdf" target="_blank">Ruber</a></u> (AAAI'18)
        </dd> -->

        <details>
        <summary> Highlights </summary>
        <table style="border:1px solid gray;margin-left:30px;margin-right:30px;border-spacing:8px;">
          <tr>
            <td style="white-space:nowrap;">Highlight 1:</td>
            <td>
                <u><a href="https://www.ijcai.org/proceedings/2018/0614.pdf" target="_blank">CMHA </a></u> (IJCAI'18), 
                <u><a href="https://arxiv.org/pdf/2004.14592.pdf" target="_blank">EnsembleGAN </a></u> (SIGIR'19), 
                <u><a href="https://aclanthology.org/P19-1538.pdf" target="_blank">MetaDial </a></u> (ACL'19), 
                <u><a href="https://aclanthology.org/2022.acl-long.68.pdf" target="_blank">ProphetChat </a></u> (ACL'22) 
            </td>
          </tr>
          
          <tr>
            <td style="white-space:nowrap;">Highlight 2:</td>
            <td> 
                [Context Modeling]
                <u><a href="https://aclanthology.org/P19-1001.pdf" target="_blank">IOI </a></u> (ACL'19),  
                <u><a href="https://dl.acm.org/doi/10.1145/3289600.3290985" target="_blank">MRFN </a></u> (WSDM'19), 
                <u><a href="https://dl.acm.org/doi/10.1145/3397271.3401290" target="_blank">ECMO</a></u> (SIGIR'20), 
                <u><a href="https://aclanthology.org/2022.findings-emnlp.539.pdf" target="_blank">IR2 </a></u> (EMNLP'22),
                <br>
                [Learning to Rank]
                <u><a href="https://aclanthology.org/P19-1370.pdf" target="_blank">CoT</a></u> (ACL'19), 
                <u><a href="https://aclanthology.org/D19-1128.pdf" target="_blank">HardSamp </a></u> (EMNLP'20), 
                <u><a href="https://dl.acm.org/doi/abs/10.1145/3488560.3498404" target="_blank">UdaRS</a></u> (WSDM'22) 
            </td>
          </tr>

          <tr>
            <td style="white-space:nowrap;">Highlight 3:</td>
            <td>    
            <u><a href="https://arxiv.org/pdf/1701.03079.pdf" target="_blank">Ruber</a></u> (AAAI'18)
            </td>
            </tr>
        </table>
        </details>
        <!-- <p style="border: 1.2px dotted gray; "> 
            <br style="line-height: 3px" />
            &nbsp;&nbsp; Highlight 1: 
                <u><a href="https://www.ijcai.org/proceedings/2018/0614.pdf" target="_blank">CMHA </a></u> (IJCAI'18), 
                <u><a href="https://arxiv.org/pdf/2004.14592.pdf" target="_blank">EnsembleGAN </a></u> (SIGIR'19), 
                <u><a href="none" target="_blank">MetaDial </a></u> (ACL'19), 
                <u><a href="none" target="_blank">ProphetChat </a></u> (ACL'22) 
            <br>
            &nbsp;&nbsp; Highlight 2: 
                [Context Modeling]
                <u><a href="https://aclanthology.org/P19-1001.pdf" target="_blank">IOI </a></u> (ACL'19),  
                <u><a href="https://dl.acm.org/doi/10.1145/3289600.3290985" target="_blank">MRFN </a></u> (WSDM'19), 
                <u><a href="none" target="_blank">ECMO</a></u> (SIGIR'20), 
                <u><a href="https://aclanthology.org/2022.findings-emnlp.539.pdf" target="_blank">IR2 </a></u> (EMNLP'22),
                <u><a href="https://www.ijcai.org/Proceedings/2019/0756.pdf" target="_blank">DGMN </a></u> (IJCAI'19),  
                <u><a href="none" target="_blank">WDMN </a></u> (TOIS'21), 
                 <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                [Learning to Rank]
                <u><a href="https://aclanthology.org/P19-1370.pdf" target="_blank">CoT</a></u> (ACL'19), 
                <u><a href="https://aclanthology.org/D19-1128.pdf" target="_blank">HardSamp </a></u> (EMNLP'20), 
                <u><a href="none" target="_blank">UdaRS</a></u> (WSDM'22) 
            <br>
            &nbsp;&nbsp; Highlight 3: 
                <u><a href="https://arxiv.org/pdf/1701.03079.pdf" target="_blank">Ruber</a></u> (AAAI'18)

            <br> 
            <br style="line-height: 8px" />
        </p>-->

    </ul>

<li> 2017/11 - 2020/02: Research Development Engineering Intern, Microsoft STCA, Beijing, China</li>
    <ul style="list-style-type:circle">
                <li>Working with Dr. Wei Wu</li>

        <li>Focus on the research of open-domain dialogue and the improvement of the core chat engine in MS.</li>
        <li>Highlight 1 (2019/03-2019/06): Participate in the design and implementation of retrieval-based modules for the empathy dialogue model in <a href="https://en.wikipedia.org/wiki/Xiaoice" target="_blank">Microsoft Rinna</a>, and help collaborators ship it to the product.</li>
        <li>Highlight 2 (2018/03-2018/06): Responsible for designing neural-based ranking features for <a href="https://en.wikipedia.org/wiki/Zo_(bot)" target="_blank">Microsoft Zo</a>.  
        <!-- The improvement to the original system on positive precision is 3.36%. -->
        </li>
    </ul>


</ul>

<!-- <a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?chongyang"
border="0" alt="Hit Counter"></a>  -->
<!-- (Unique visitors since Jul 2021) -->

<!-- </section>
<section> -->

<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=A1Qps90KPni514lR4iRmyjiOABlmWA4IA9o7qVyPeqI&cl=ffffff&w=a"></script> -->
<br>


<!-- <em>
Doing things matters and doing research that matters!
</em><br> &nbsp;
&ndash;Donald E. Knuth, <i>Stanford University</i>
</em><br> &nbsp; -->


<!-- 
<table width="50%" align="center" border="0" cellpadding="20"><tbody>
  <tr>
    <td width="50%" valign="center"></td>       
      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=A1Qps90KPni514lR4iRmyjiOABlmWA4IA9o7qVyPeqI'></script>
    </td>
  </tr>
</tbody></table> -->




</section>


<section>
<h2> Publications (<a href="https://scholar.google.com/citations?user=x_cOKuwAAAAJ" target="_blank">Google Scholar</a>)</h2>
<br>


<h3>Preprint</h3>
<ul>

<li> <u>Xiaohan Xu</u>, Ming Li, <strong><strong>Chongyang Tao</strong></strong>, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, Tianyi Zhou. <strong><a href="https://arxiv.org/pdf/2402.13116.pdf" target="_blank">A Survey on Knowledge Distillation of Large Language Models</a></strong>. In <em>Arxiv</em> <b>(2024)</b>, 2024.02.
<img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle">
</li>


<li> Yibin Lei, Di Wu, Tao, Shen, Yu Cao, <strong><strong>Chongyang Tao</strong></strong>, Andrew Yates. <strong><a href="https://arxiv.org/pdf/2402.18458.pdf" target="_blank">Meta-Task Prompting Elicits Embedding from Large Language Models</a></strong>. In <em>Arxiv</em> <b>(2024)</b>, 2024.02.
<img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle">
</li>



<li> Kaiwen Yang, Tao Shen, Xinmei Tian, Xiubo Geng, <strong><strong>Chongyang Tao</strong></strong>, Dacheng Tao, Tianyi Zhou. <strong><a href="https://arxiv.org/pdf/2312.01598.pdf" target="_blank">Good Questions Help Zero-Shot Image Reasoning</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.12.
<img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle">
</li>



<li> Yucheng Zhou, Xiubo Geng, Tao Shen, <strong><strong>Chongyang Tao</strong></strong>, Guodong Long, Jianguang Lou. <strong><a href="https://arxiv.org/pdf/2311.08734.pdf" target="_blank">Thread of thought unraveling chaotic contexts</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.11.
<img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle">
</li>


<li> <u>Jia Li</u>, Ge Li, <strong><strong>Chongyang Tao</strong></strong>, Hai Zhang, Fang Liu, Zhi Jin. <strong><a href="https://arxiv.org/pdf/2310.09748.pdf" target="_blank">Large Language Model-Aware In-Context Learning for Code Generation</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.11.
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</li>



<li> <u>Xiaohan Xu</u>, <strong><strong>Chongyang Tao</strong></strong>, Tao Shen, Can Xu, Hongbo Xu, Guodong Long, Jian-guang Lou. <strong><a href="https://arxiv.org/pdf/2309.06275.pdf" target="_blank">Re-Reading Improves Reasoning in Language Models</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.09.
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</li>


<li> <u>Jiazhan Feng</u>*, <strong>Chongyang Tao</strong>*, Xiubo Geng, Tao Shen, Can Xu, Guodong Long, Dongyan Zhao, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2305.07402" target="_blank">Knowledge Refinement via Interaction Between Search Engines and Large Language Models</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.05.
<a href="https://github.com/Cyril-JZ/InteR" target="_blank"><b>[Code]</b></a> 
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</li>



<li> Ziyang Luo, Can Xu, Pu Zhao, Xiubo Geng, <strong>Chongyang Tao</strong>, Jing Ma, Qingwei Lin, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2305.04757" target="_blank">Augmented Large Language Models with Parametric Knowledge Guiding</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.05.
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</a></li>


<li> Tao Shen, Guodong Long, Xiubo Geng, <strong>Chongyang Tao</strong>, Tianyi Zhou, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2304.14233" target="_blank">Large Language Models are Strong Zero-Shot Retriever</a></strong>. In <em>Arxiv</em> <b>(2023)</b>, 2023.04.
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</li> 

<li> <u>Chang Liu</u>*, <strong>Chongyang Tao</strong>*, Xiubo Geng, Tao Shen, Dongyan Zhao, Can Xu, Binxing Jiao, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2212.10192" target="_blank">Adam: Dense Retrieval Distillation with Adaptive Dark Examples</a></strong>. In <em>Arxiv</em> <b>(2022)</b>, 2022.12 </a>
</li> 


<!-- \item \textbf{<strong>Chongyang Tao</strong>}, Ruijian Xu, Chang Liu. \textit{Can Reference-free Dialogue Evaluation Models Help Open-domain Response Generation?} Submitted to ICASSP-2023.  -->
  






</ul>



<h3>2024</h3>
<ul>
<li> Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Jiazhan Feng, <strong>Chongyang Tao</strong>, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2304.12244" target="_blank">WizadLM: Empowering Large Language Models to Follow Complex Instructions    </a></strong>.In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2024)</b>, 2024.02.
<a href="https://github.com/nlpxucan/WizardLM" target="_blank"><b>[Code]</b></a> 
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</li>

<li> Ziyang Luo*, Can Xu*, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, <strong>Chongyang Tao</strong>, Jing Ma, Qingwei Lin, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2306.08568" target="_blank">WizardCoder: Empowering Code Large Language Models with Evol-Instruct</a></strong>. In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2024)</b>, 2024.02.
<a href="https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder" target="_blank"><b>[Code]</b></a> 
<!-- <img src="new_card.png" alt="Smiley face" width="30" height="25" style="vertical-align:middle"> -->
</li>

<li> Yucheng Zhou, Tao Shen, Xiubo Geng, <strong>Chongyang Tao</strong>, Guodong Long, Can Xu, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2212.10423" target="_blank">Fine-Grained Distillation for Long Document Retrieval</a></strong>. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> <b>(AAAI 2024)</b> </a>
</li>

<li> Yang Li, Canran Xu, Guodong Long, Tao Shen, Chongyang Tao, Jing Jiang. <strong><a href="https://arxiv.org/pdf/2212.10423" target="_blank">CCPrefix: Counter- factual Contrastive Prefix-Tuning for Many-Class Classification</a></strong>. In <em>Proceedings of the European Chapter of the Association for Computational Linguistics </em> <b>(EACL 2024)</b> </a>
</li>


</ul>





<h3>2023</h3>
<ul>


<li> Ziyang Luo, Pu Zhao, Can Xu, Xiubo Geng, Tao Shen, <strong>Chongyang Tao</strong>, Jing Ma, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2302.02908.pdf" target="_blank">LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Retrieval</a></strong>. In <em>Proceeding of the International Conference on Computer Vision</em> <b>(ICCV 2023)</b>, 2023.08.
</li>

<li> Tao Shen, Xiubo Geng, <strong>Chongyang Tao</strong>, Can Xu, Kai Zhang, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2205.11194.pdf" target="_blank">UnifieR: A Unified Retriever for Large-Scale Retrieval</a></strong>. In <em>Proceeding of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em> <b>(SIGKDD 2023)</b>, 2023.07.
<a href="https://github.com/taoshen58/UnifieR" target="_blank"><b>[Code]</b></a> 
</li>
<!-- , <mark>Oral</mark> -->

<li> <strong>Chongyang Tao</strong>, Tao Shen, Jiazhan Feng, Chang Liu, Juntao Li, Xiubo Geng, Daxin Jiang. <strong><a href="https://aclanthology.org/2023.acl-long.174.pdf" target="_blank">CoRe: Cooperative Training of Retriever-Reranker for Effective Dialogue Response Selection</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7. 
</li>

<li> <u>Zhen Li</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Jiazhan Feng, Tao Shen, Dongyan Zhao, Xiubo Geng and Daxin Jiang. <strong><a href="https://aclanthology.org/2023.acl-long.94.pdf" target="_blank">FAA: Fine-grained Attention Alignment for Cascade Document Ranking</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7.  
</li>
<!-- , <mark>Oral</mark> -->

<li>  <u>Xiuyin Chen</u><sup>+</sup>, Guodong Long, <strong>Chongyang Tao</strong>, Xing Gao, Chengqi Zhang, Xiangliang Zhang. <strong><a href="https://aclanthology.org/2023.acl-long.378.pdf" target="_blank">Improving the Robustness of Summarization Systems with Dual Augmentation</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7.  
<a href="https://github.com/iriscxy/robustness" target="_blank"><b>[Code]</b></a> 
</li>

<li> <u>Jiazhan Feng</u><sup>+</sup>, Qingfeng Sun, Can Xu, Pu Zhao, Yaming Yang, <strong>Chongyang Tao</strong>, Dongyan Zhao, Qingwei Li. <strong><a href="https://aclanthology.org/2023.acl-long.405.pdf" target="_blank">MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal Open-domain Conversation</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7.
<a href="https://github.com/victorsungo/MMDialog" target="_blank"><b>[Dataset]</b></a> 
</li>


<!-- Zhengwei Tao, Zhi Jin, Haiyan Zhao, Chengfeng Dou, Yongqiang Zhao, Tao Shen,<strong>Chongyang Tao</strong>. Unified Generative Model with Multi-Dimensional Prefix for Zero-Shot Event-Relational Reasoning. In ACL-2023. (Full Paper, CCF-A) -->


<!-- Zhengwei Tao, Zhi Jin, Xiaoying Bai, Haiyan Zhao, Fang Wang, Chengfeng Dou, Yongqiang Zhao, <strong>Chongyang Tao</strong>. SEAG: Structure-Aware Event Causality Generation. In Findings of ACL-2023. (Full Paper) -->


<li>  Yucheng Zhou, Tao Shen, Xiubo Geng, <strong>Chongyang Tao</strong>, Can Xu, Guodong Long, Binxing Jiao, Daxin Jiang. <strong><a href="https://aclanthology.org/2023.findings-acl.332.pdf" target="_blank">Towards Robust Ranker for Text Retrieval</a></strong>. In <em>Findings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(Findings of ACL 2023)</b>, Toronto, Canada, 2023.7.  
</li>


<!-- Jianxin Liang, Chang Liu, <strong>Chongyang Tao</strong>, Jiazhan Feng and Dongyan Zhao. Attend, Select and Eliminate: Accelerating Multi-turn Response Selection with Dual-attention-based Content Elimination. In Findings of ACL-2023. (Full Paper，已接收) -->

<!-- Jiazhan Feng, <strong>Chongyang Tao</strong>, Tao Shen, Chang Liu, Dongyan Zhao. D2KM: Dimension-Disentangled Knowledge Model for Commonsense Graph Construction. In SIGIR-2023. (Short Paper, CCF-A) -->


<li> <u>Kai Zhang</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Tao Shen, Can Xu, Xiubo Geng, Binxing Jiao, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2208.13661.pdf" target="_blank">LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval</a></strong>. In <em>Proceedings of the International World Wide Web Conference</em> <b>(WWW 2023)</b>, 2023.01.
<a href="https://github.com/drogozhang/LED" target="_blank"><b>[Code]</b></a> 
</li>



<li> <u>Zefeng Cai</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Tao Shen, Can Xu, Xiubo Geng, Xin Alex Lin, Liang He, and Daxin Jiang. <strong><a href="https://openreview.net/forum?id=kUf4BcWXGJr" target="_blank">HypeR: Multitask Hyper-Prompted Training Enables Large-Scale Retrieval Generalization</a></strong>. In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, 2023.01.
<a href="https://github.com/oklen/HypeR" target="_blank"><b>[Code]</b></a> 
</li>

<li> Tao Shen, Xiubo Geng, <strong>Chongyang Tao</strong>, Can Xu, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2208.14754.pdf" target="_blank">LexMAE: Lexicon-Bottlenecked Pretraining for Large-Scale Retrieval</a></strong>. In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, 2023.01.
<a href="https://github.com/taoshen58/LexMAE" target="_blank"><b>[Code]</b></a> 
</li>


<li> Yufei Wang, Jiayi Zheng, Can Xu, Xiubo Geng, Tao Shen, <strong>Chongyang Tao</strong>, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2206.10265.pdf" target="_blank">KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP</a></strong>. 
In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, 2023.01.
<a href="https://github.com/GaryYufei/ICLR2023_KnowDA" target="_blank"><b>[Code]</b></a> 
</li>


<li> <u>Jiazhan Feng</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Xueliang Zhao, Rui Yan, Dongyan Zhao. <strong><a href="https://dl.acm.org/doi/10.1145/3584701" target="_blank">Learning Multi-turn Response Selection in Grounded Dialogues with Reinforced Knowledge and Context Distillation</a></strong>. In <em> ACM Transactions on Information Systems, Volume 41, Issue 4, Article No.115.</em> <b>(TOIS 2023)</b>, 2023.4.
</li>


</ul>



<h3>2022</h3>
<ul>

<li> <u>Qiyu Wu</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Tao Shen, Can Xu, Xiubo Geng, Daxin Jiang. <strong><a href="https://aclanthology.org/2022.emnlp-main.826.pdf" target="_blank">PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, 2022.11.
<a href="https://github.com/qiyuw/PeerCL" target="_blank"><b>[Code]</b></a> 
</li>

<li> <u>Chang Liu</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Jianxin Liang, Tao Shen, Jiazhan Feng, Quzhe Huang, Dongyan Zhao. <strong><a href="https://aclanthology.org/2022.emnlp-main.729.pdf" target="_blank">Rethinking Task-Specific Knowledge Distillation: Contextualized Corpus as Better Textbook</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, 2022.11</li>

<li> <u>Jiazhan Feng</u>, <strong>Chongyang Tao</strong>, Chang Liu, Rui Yan, Dongyan Zhao. <strong><a href="https://aclanthology.org/2022.findings-emnlp.539.pdf" target="_blank">How to Represent Context Better? An Empirical Study on Context Modeling for Multi-turn Response Selection</a></strong>. In <em>Findings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, 2022.11</li>


<li> Tingchen Fu*, <u>Xueliang Zhao</u>*, <strong>Chongyang Tao</strong>, Rui Yan, Ji-Rong Wen. <strong><a href="https://aclanthology.org/2022.emnlp-main.123.pdf" target="_blank">There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, 2022.11</li>

<li> Xueliang Zhao, Yuxuan Wang, <strong>Chongyang Tao</strong>, Chenshuo Wang, Dongyan Zhao. <strong><a href="https://aclanthology.org/2022.findings-emnlp.442.pdf" target="_blank">Collaborative Reasoning on Multi-Modal Semantic Graphs for Video-Grounded Dialogue Generation</a></strong>. In <em>Findings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, 2022.11</li>


<!-- <li> Jiazhan Feng, <strong>Chongyang Tao</strong>, Chang Liu, Tao Shen, Chang Liu, Dongyan Zhao. <strong><a href="https://aclanthology.org/2022.coling-1.31.pdf" target="_blank">Reciprocal Learning of Knowledge Retriever and Response Ranker for Knowledge-Grounded Conversations.</a></strong>. In <em>Proceedings of the International Conference on Computational Linguistics</em> <b>(COLING 2022)</b>, 2022.11</li> -->


<!-- <li> Lia Li, Yuyuan Zhao, Zhi Jin, Ge Li, Tao Shen, Zhengwei Tao, <strong>Chongyang Tao</strong>. <strong><a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557452" target="_blank">SK2: Integrating Implicit Sentiment and Explicit Syntax Knowledge for ABSA.</a></strong>. In <em>Proceedings of the 31th ACM International Conference on Information and Knowledge Management</em> <b>(CIKM 2022)</b>, 2022.11</li> -->


<li><u>Xueliang Zhao</u>, Tingchen Fu, <strong>Chongyang Tao</strong>, Wei Wu, Dongyan Zhao, Rui Yan. <strong><a href="https://aclanthology.org/2022.naacl-main.164.pdf" target="_blank">Learning to Express in Knowledge-Grounded Conversation</a></strong>. In <em>Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies</em> <b>(NAACL-HLT 2022)</b>, Seattle, Washington, 2022.7 </li>
<!-- , <mark>Oral</mark> -->

<li><u>Jia-chen Gu</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Zhen-Hua Ling. <strong><a href="https://www.ijcai.org/proceedings/2022/768" target="_blank">Who Says What to Whom: A Survey of Multi-Party Conversations</a></strong>. In <em>Proceedings of the 31th International Joint Conference on Artificial Intelligence</em> <b>(IJCAI 2022)</b>, Vienna, Austria, 2022.7 </li>

<li><u>Jia-Chen Gu</u><sup>+</sup>, Chao-Hong Tan<sup>+</sup>, <strong>Chongyang Tao</strong>, Zhen-Hua Ling, Huang Hu, Xiubo Geng, Daxin Jiang. <strong><a href="https://aclanthology.org/2022.acl-long.349.pdf" target="_blank">HeterMPC: A Heterogeneous Graph Neural Network for Response Generation in Multi-Party Conversations</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, Dublin, Ireland, 2022.5.  <a href="https://github.com/JasonForJoy/MPC-BERT" target="_blank"><b>[Code]</b></a> </li>


<li><u>Chang Liu</u>, <strong>Chongyang Tao</strong>, Jiazhan Feng, Dongyan Zhao. <strong><a href="https://aclanthology.org/2022.acl-long.71.pdf" target="_blank">Multi-Granularity Structural Knowledge Distillation for Language Model Compression</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, Dublin, Ireland, 2022.5.
<a href="https://github.com/LC97-pku/MGSKD" target="_blank"><b>[Code]</b></a>
</li>


<!-- <li>Zhen Li, Jiazhan Feng, <strong>Chongyang Tao</strong>, Dongyan Zhao. <strong><a href="https://dl.acm.org/doi/abs/10.1007/978-3-031-17120-8_37" target="_blank">Training Two-Stage Knowledge-grounded Dialogue with Attention Feedback</a></strong>. In <em>Proceedings of Natural Language Processing and Chinese Computing</em> <b>(NLPCC 2022)</b>,2022 </li> -->



<li><u>Chang Liu</u>, Xu Tan, <strong>Chongyang Tao</strong>, Zhenxin Fu, Dongyan Zhao, Tie-Yan Liu, Rui Yan. <strong><a href="https://aclanthology.org/2022.acl-long.68.pdf" target="_blank">ProphetChat: Enhancing Dialogue Generation with Simulation of Future Conversation</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, Dublin, Ireland, 2022.5 </li>


<li>Tingchen Fu*, <u>Xueliang Zhao</u>*, <strong>Chongyang Tao</strong>, Ji-Rong Wen, Rui Yan. <strong><a href="https://aclanthology.org/2022.acl-long.270.pdf" target="_blank">There Are a Thousand Hamlets in a Thousand People's Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, Dublin, Ireland, 2022.5 </li>


<li>Yufei Wang, Can Xu, Qingfeng Sun, Huang Hu, <strong>Chongyang Tao</strong>, Xiubo Geng, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2202.12499.pdf" target="_blank">Prompt-based Data Augmentation for Low-Resource NLU Tasks</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, Dublin, Ireland, 2022.5
<a href="https://github.com/GaryYufei/PromDA" target="_blank"><b>[Code]</b></a> 
</li>


<li><u>Chao-Hong Tan</u><sup>+</sup>, <u>Jia-Chen Gu</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Zhen-Hua Ling, Can Xu, Huang Hu, Xiubo Geng, Daxin Jiang. <strong><a href="https://aclanthology.org/2022.findings-acl.125.pdf" target="_blank">TegTok: Augmenting Text Generation via Task-specific and Open-world Knowledge</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022 Findings)</b>, Dublin, Ireland, 2022.5.
<a href="https://github.com/lxchtan/TegTok" target="_blank"><b>[Code]</b></a> 
</li>

<li><u>Jia Li</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Huang Hu, Can Xu, Yining Chen and Daxin Jiang. <strong><a href="https://dl.acm.org/doi/abs/10.1145/3488560.3498404" target="_blank">Unsupervised Cross-Domain Adaptation for Response Selection Using Self-Supervised and Adversarial Training</a></strong>. In <em>Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</em> <b>(WSDM 2022)</b>, Phoenix, Arizona, 2022.2 </li>



</ul>



<h3>2021</h3>
<ul>

<li> Yufei Wang, Can Xu, Huang Hu, <strong>Chongyang Tao</strong>, Stephen Wan, Mark Dras, Mark Johnson, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2107.13077.pdf" target="_blank">Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation</a></strong>. In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2021)</b>, 2021.11 </a>
<a href="hhttps://slideslive.com/38968718/neural-ruleexecution-tracking-machine-for-transformerbased-text-generation?ref=speaker-33161" target="_blank"><b>[Video]</b></a> 
</li>


<li> <u>Jia-Chen Gu</u><sup>+</sup>, <strong>Chongyang Tao</strong>, Zhenhua Ling, Can Xu, Xiubo Geng, Daxin Jiang. <strong><a href="https://aclanthology.org/2021.acl-long.285.pdf" target="_blank">MPC-BERT: A Pre-Trained Language Model for Multi-Party Conversation Understanding</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8
<a href="https://github.com/JasonForJoy/MPC-BERT" target="_blank"><b>[Code]</b></a>
</li>
<!-- , <mark>Oral</mark> -->

<li> Zujie Liang, Huang Hu, Can Xu, <strong>Chongyang Tao</strong>, Xiubo Geng, Yining Chen, Fan Liang, Daxin Jiang. <strong><a href="https://arxiv.org/pdf/2105.13073.pdf" target="_blank">Maria: A Visual Experience Powered Conversational Agent</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8 
<a href="https://github.com/jokieleung/Maria" target="_blank"><b>[Code]</b></a>
</li>


<li> <strong>Chongyang Tao</strong>, Changyu Chen, Jiazhan Feng, Ji-Rong Wen, Rui Yan. <strong><a href="https://aclanthology.org/2021.acl-long.343.pdf" target="_blank">A Pre-training Strategy for Zero-Resource Response Selection in Knowledge-Grounded Conversations</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8 </li>


<li> <strong>Chongyang Tao</strong>, Jiazhan Feng, Rui Yan, Wei Wu, Daxin Jiang. <strong><a href="https://www.ijcai.org/proceedings/2021/0627.pdf" target="_blank">A Survey on Response Selection for Retrieval-based Dialogues</a></strong>. In <em>Proceedings of the 30th International Joint Conference on Artificial Intelligence</em> <b>(IJCAI 2021)</b>, 2021.8 </li>

<li> <strong>Chongyang Tao</strong>, Shen Gao, Juntao Li, Yansong Feng, Dongyan Zhao, Rui Yan. <strong><a href="https://aclanthology.org/2021.naacl-main.134.pdf" target="_blank">Learning to Organize a Bag of Words into Sentences with Neural Networks: An Empirical Study</a></strong>. In <em>Proceedings of the North American Chapter of the Association for Computational Linguistics</em> <b>(NAACL 2021)</b>, 2021.6 </li>

<li> <u>Ruijian Xu</u>, <strong>Chongyang Tao</strong>, Jiazhan Feng, Wei Wu, Rui Yan, Dongyan Zhao. <strong><a href="https://dl.acm.org/doi/10.1145/3462207" target="_blank">Response Ranking with Multi-types of Deep Interactive Representations in Retrieval-based Dialogues</a></strong>. In <em> ACM Transactions on Information Systems, Volume 39, Issue 4</em> <b>(TOIS 2021)</b>, 2021.8 </li>

<li> <u>Ruijian Xu</u>, <strong>Chongyang Tao</strong>, Daxin Jiang, Xueliang Zhao, Dongyan Zhao, Rui Yan. <strong><a href="https://arxiv.org/pdf/2009.06265.pdf" target="_blank">Learning an Effective Context-Response Matching Model with Self-Supervised Tasks for Retrieval-based Dialogues</a></strong>. In <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> <b>(AAAI 2021)</b>, 2021.2.
<a href="https://github.com/RayXu14/SL4DU" target="_blank"><b>[Code]</b></a>

</li>




<li> Juntao Li*, Chang Liu*, <strong>Chongyang Tao</strong>, Zhangming Chan, Dongyan Zhao, Rui Yan. <strong><a href="https://arxiv.org/pdf/2103.09534.pdf" target="_blank">Dialogue History Matters! Personalized Response Selectionin Multi-turn Retrieval-based Chatbots</a></strong>. In <em> ACM Transactions on Information Systems, Volume 39, Issue 4</em> <b>(TOIS 2021)</b>, 2021.2 </li>

</ul>


<h3>2020</h3>
<ul>
<li> Linxiao Li, Can Xu, Wei Wu, Yufan Zhao, Xueliang Zhao, <strong>Chongyang Tao</strong>. <strong><a href="https://arxiv.org/pdf/2008.12918.pdf" target="_blank">Zero-Resource Knowledge-Grounded Dialogue Generation</a></strong>. In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2020)</b>, 2020.12 <a href="https://github.com/nlpxucan/ZRKGC" target="_blank"><b>[Code]</b></a></li>

<li> Xueliang Zhao, Wei Wu, Can Xu, <strong>Chongyang Tao</strong>, Dongyan Zhao, Rui Yan. <strong><a href="https://www.aclweb.org/anthology/2020.emnlp-main.272" target="_blank">Knowledge-Grounded Dialogue Generation with Pre-trained Language Models</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2020)</b>, 2020.11 <a href="https://github.com/zhaoxlpku/KnowledGPT" target="_blank"><b>[Code]</b></a></li>

<li> <u>Kai Hua</u><sup>+</sup>, <u>Zhiyuan Feng</u>, <strong>Chongyang Tao</strong>, Rui Yan, Lu Zhang. <strong><a href="https://dl.acm.org/doi/abs/10.1145/3340531.3411967" target="_blank">Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems</a></strong>. In <em>Proceedings of the 29th ACM International Conference on Information and Knowledge Management</em> <b>(CIKM 2020)</b>, 2020.10 </li>

<li> <strong>Chongyang Tao</strong>, Wei Wu, Yansong Feng, Dongyan Zhao, Rui Yan. <strong><a href="https://dl.acm.org/doi/10.1145/3397271.3401290" target="_blank">Improving Matching Models with Hierarchical Contextualized Representations for Multi-turn Response Selection</a></strong>. In <em>Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</em> <b>(SIGIR 2020)</b>, 2020.07 </li>

<li> <u>Xueliang Zhao</u>, Wei Wu, <strong>Chongyang Tao</strong>, Can Xu, Dongyan Zhao, Rui Yan. <strong><a href="https://openreview.net/pdf?id=rJeIcTNtvS" target="_blank">Low-Resource Knowledge-Grounded Dialogue Generation</a></strong>. In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2020)</b>, 2020.4 </li>


</ul>


<h3>2019</h3>
<ul>

<li> <strong>Chongyang Tao</strong>, Wei Wu, Can Xu, Wenpeng Hu, Dongyan Zhao and Rui Yan. <strong><a href="https://aclanthology.org/P19-1001.pdf" target="_blank">One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues </a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2019)</b>, Florence, Italy, 2019.7 <a href="https://github.com/chongyangtao/IOI" target="_blank"><b>[Code]</b></a></li>
<!-- , <mark>Oral</mark> -->

<li> Jiazhan Feng*, <strong>Chongyang Tao</strong>*, Wei Wu, Yansong Feng, Dongyan Zhao and Rui Yan. <strong><a href="https://aclanthology.org/P19-1370.pdf" target="_blank">Learning a Matching Model with Co-teaching for Multi-turn Response Selection in Retrieval-based Dialogue Systems</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, Florence, Italy, 2019.7 </li>

<li>Can Xu, Wei Wu, <strong>Chongyang Tao</strong>, Huang Hu and Matt Schuerman. <strong><a href="https://aclanthology.org/P19-1538.pdf" target="_blank">Neural Response Generation with Meta-words</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2019)</b>, Florence, Italy, 2019.7 </li>

<li>Xueliang Zhao*, <strong>Chongyang Tao</strong>*, Wei Wu, Yansong Feng, Dongyan Zhao and Rui Yan. <strong><a href="https://www.ijcai.org/Proceedings/2019/0756.pdf" target="_blank">A Document-grounded Matching Network for Response Selection in Retrieval-based Chatbots</a></strong>. In <em>Proceedings of the 27th International Joint Conference on Artificial Intelligence</em> <b>(IJCAI 2019)</b>, Macao, China, 2019.8 </li>

<li>Jiayi Zhang*, <strong>Chongyang Tao</strong>*, Zhenjing Xu, Qiaojing Xie, Wei Chen and Rui Yan. <strong><a href="https://arxiv.org/pdf/2004.14592.pdf" target="_blank">EnsembleGAN: Adversarial Learning for Retrieval-Generation Ensemble Model on Short-Text Conversation</a></strong>. In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(SIGIR 2019)</b>, Paris, France, 2019.7 </li>
<!-- , <mark>Oral</mark> -->

<li>Jia Li, <strong>Chongyang Tao</strong>, Wei Wu, Yansong Feng, Dongyan Zhao, Rui Yan. <strong><a href="https://aclanthology.org/D19-1128.pdf" target="_blank">Sampling Matters! An Empirical Study of Negative Sampling Strategies for Learning of Matching Models in Retrieval-based Dialogue Systems</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2019)</b>, Hong Kong, China, 2019.11</li>

<li>Wenpeng Hu, Zhou Lin, Bin Liu, <strong>Chongyang Tao</strong>, Zhengwei Tao,  Jinwen Ma, Dongyan Zhao and Rui Yan. <strong><a href="https://openreview.net/forum?id=ryGvcoA5YX" target="_blank">Overcoming Catastrophic Forgetting via Model Adaptation</a></strong>. In <em>Proceedings of the International Conference on Learning Representations</em> <b>(ICLR 2019)</b>, New Orleans, Louisiana, 2019.7 <a href="https://github.com/morning-dews/PGMA_tensorflow" target="_blank"><b>[Code]</b></a></li>

<!-- <li>Jia Li, <strong>Chongyang Tao</strong>, Nanyun Peng, Wei Wu, Dongyan Zhao, Rui Yan.<strong><a href="https://link.springer.com/chapter/10.1007/978-3-030-32233-5_12" target="_blank">Evaluating and Enhancing the Robustness of Retrieval-Based Dialogue Systems with Adversarial Examples</a></strong>. In <em>Proceedings of the CCF International Conference on Natural Language Processing and Chinese Computing</em> <b>(NLPCC 2019)</b>, Dunhuang, China, 2019.7 </li> -->

<li>Xiaoye Tan, Rui Yan, <strong>Chongyang Tao</strong>, Mingrui Wu.<strong><a href="https://arxiv.org/pdf/1906.07525.pdf" target="_blank">Mimicking Human Process: Text Representation via Latent Semantic Clustering for Classification</a></strong>. In <em>Proceedings of the CCF International Conference on Natural Language Processing and Chinese Computing</em> <b>(NLPCC 2019 & 2nd workshop of HAI at IJCAI 2019, <b style="color:red">Outstanding Paper Award</b>)</b>  , Dunhuang, China, 2019.7 </li>


<li><strong>Chongyang Tao</strong>, Wei Wu, Can Xu, Wenpeng Hu, Dongyan Zhao and Rui Yan. <strong><a href="https://dl.acm.org/doi/10.1145/3289600.3290985" target="_blank">Multi-Representation Fusion Network for Multi-turn Response Selection in Retrieval-based Chatbots</a></strong>. In <em>Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</em> <b>(WSDM 2019)</b>, Melbourne, Australia, 2019.2 <a href="https://github.com/chongyangtao/MRFN" target="_blank"><b>[Code]</b></a></li>


</ul>


<h3>2018</h3>
<ul>

<li> Xiuying Chen, Shen Gao, <strong>Chongyang Tao</strong>, Dongyan Zhao and Rui Yan. <strong><a href="https://aclanthology.org/D18-1442.pdf" target="_blank">Iterative Document Representation Learning Towards Summarization with Polishing</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2018)</b>, Brussels, Belgium, 2018.11 <a href="https://github.com/iriscxy/Iterative-Document-Representation-Learning-Towards-Summarization-with-Polishing" target="_blank"><b>[Code]</b></a></li>

<li> Huang Hu, Xianchao Wu, Bingfeng Luo, <strong>Chongyang Tao</strong>, Can Xu, Wei Wu and Zhan Chen. <strong><a href="http://aclweb.org/anthology/D18-1361" target="_blank">Playing 20 Question Game with Policy-Based Reinforcement Learning</a></strong>. In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2018)</b>, Brussels, Belgium, 2018.11 <a href="https://github.com/stonyhu/Q20-DeepRL" target="_blank"><b>[Code]</b></a></li>

<li> <strong>Chongyang Tao</strong>, Shen Gao, Mingyue Shang, Wei Wu, Dongyan Zhao and Rui Yan. <strong><a href="https://www.ijcai.org/proceedings/2018/0614.pdf" target="_blank">Get The Point of My Utterance! Learning Towards Effective Responses with Multi-Head Attention Mechanism </a></strong>. In <em>Proceedings of the 27th International Joint Conference on Artificial Intelligence</em> <b>(IJCAI 2018)</b>, Stockholm, Sweden, 2018.7 </li>

<li> <strong>Chongyang Tao</strong>, Lili Mou, Dongyan Zhao and Rui Yan. <strong><a href="https://arxiv.org/pdf/1701.03079.pdf" target="_blank">RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems</a></strong>. In <em>Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</em> <b>(AAAI 2018)</b>, New Orleans, Louisiana, 2018.2 </li>
</ul>


<p>*means equal contribution, <sup>#</sup>means the corresponding author.
<!-- and <u>underline</u> indicates students mentored by me at Microsoft. </p> -->




</section>
</body>
</html>

